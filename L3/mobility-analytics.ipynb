{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trajectory data mining in Python\n",
    "\n",
    "In this tutorial, we will learn how to conduct exploratory space-time data analysis (ESTDA) based on movement data. When analyzing mobility data, using various visualization approaches (visual analytics) is important to be able to understand the data and extract insights from it. Here, we will learn a few tricks how we can manipulate movement data and visualize it using static and interactive visualizations in Python. \n",
    "\n",
    "```{admonition} Attribution\n",
    "\n",
    "This tutorial is partly based on excellent resources provided by Anita Graser and the documentation of `movingpandas` [library](https://github.com/anitagraser/movingpandas).\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keplergl import KeplerGl\n",
    "import geopandas as gpd\n",
    "import movingpandas as mpd\n",
    "from datetime import datetime, timedelta\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data\n",
    "\n",
    "In this tutorial, we will use AIS data that describes vessel movements ([obtained from movingpandas](https://github.com/anitagraser/movingpandas-examples/tree/main/data)). The AIS data has been published by the Danish Maritime Authority. The AIS record sample extracted for this tutorial covers vessel traffic on the 5th July 2017 near Gothenburg. Let's start by reading it and checking how the data looks like: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath\n",
    "fp = \"data/ais.gpkg\"\n",
    "data = gpd.read_file(fp);\n",
    "data.plot(figsize=(12,12), markersize=0.7, alpha=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check first rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay as we can see, we have around 80,000 recorded observations and information about the timestamp, geometry, ship type etc. `SOG` column contains information about speed over ground. Let's take a look at the data distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SOG'].hist(bins=100, figsize=(15,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, most of the observations are actually such where the vessels have not been moving, i.e. they are staying at the harbor. It is not useful to keep such records in our data, so let's get rid off those: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.SOG>0].copy()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we have much less observations. Let's at this point calculate `x` and `y` coordinates based on our Point geometries, so that we can easily plot our data in 3D:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate x and y coordinates\n",
    "data[\"x\"] = data[\"geometry\"].x\n",
    "data[\"y\"] = data[\"geometry\"].y\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing trajectories\n",
    "\n",
    "Next, we want to convert our individual point observations into **trajectories**. This can be done easily using the ``TrajectoryCollection`` functionality / class provided by movingpandas (see [docs](https://movingpandas.readthedocs.io/en/latest/trajectorycollection.html)). To be able to use this functionality, we first need to parse a ``DateTime`` index based on the ``Timestamp`` column, and that the `MMSI` number (*Maritime Mobile Service Idenity*) is used as the unique id for a ship. We also specify that the minimum length for a trajectory needs to be at least 100 meters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trajectories\n",
    "data['time'] = pd.to_datetime(data['Timestamp'], format='%d/%m/%Y %H:%M:%S')\n",
    "data = data.set_index('time')\n",
    "\n",
    "# Specify minimum length for a trajectory (in meters)\n",
    "minimum_length = 100 \n",
    "collection = mpd.TrajectoryCollection(data, 'MMSI', min_length=minimum_length)\n",
    "\n",
    "# What did we get?\n",
    "collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, we get an object that represents the collection of trajectories identified by movingpandas. We can plot all the trajectories easily by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot all trajectories\n",
    "collection.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access each of these trajectories individually by looping over our collection. We can also easily calculate the speed and add information about the direction of movement to our data by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for trajectory in collection.trajectories:\n",
    "    # Calculate speed\n",
    "    trajectory.add_speed(overwrite=True)\n",
    "    \n",
    "    # Determine direction of movement\n",
    "    trajectory.add_direction(overwrite=True)\n",
    "    \n",
    "    # Let's first check only the first trajectory (i.e. stop iteration after first run)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what we got. We can access the DataFrame of the given trajectory by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory.df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, now we have new columns `speed` and `direction` added to the data which contain information about the speed and direction. We can plot the single trajectory using geopandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kind of individual trajectory is not very informative as such. We can add more context to our visualization by adding a background map and making it interactive. Movingpandas provides an easy-to-use api to plot the trajectory on top of OSM basemap with Holoviews/Bokeh:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory.hvplot(frame_height=400, frame_width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This map provides much more contextual information and makes it possible to understand that the trajectory is a ship which is approaching or leaving the harbor of Gothenburg (tricky to say at this point). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory analysis with Space Time Cube (STC)\n",
    "\n",
    "It is also fairly easy to visualize our trajectory in 3D using space time cube, in which the 3rd dimension is based on time. There are different libraries that can be used for plotting data in 3D, but we will use here [plotly](https://plotly.com/python/plotly-express/) library which provides a relatively easy and straightforward API to generate 3D visualizations. For plotting data in 3D Let's first modify our datetime information a bit, and only keep the time because all of our values are from the same date (5th of July, 2017): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the time component\n",
    "trajectory.df[\"time\"] = pd.to_datetime(trajectory.df[\"Timestamp\"]).dt.strftime(\"%H:%M\")\n",
    "\n",
    "# Plot the trajectory in space-time cube\n",
    "fig = px.line_3d(trajectory.df, x=\"x\", y=\"y\", z=\"time\", color='MMSI')\n",
    "fig.update_traces(line=dict(width=5))\n",
    "\n",
    "# Want to get background map as well? It is possible:\n",
    "# https://chart-studio.plotly.com/~empet/14397/plotly-plot-of-a-map-from-data-available/#/\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we can see our trajectory in 3D! Based on this viusalization we can already understand our data a bit better. We can for example, see how the ship has slowly approached the harbor and then docked around 18:00 when the movement has stopped (i.e. x/y coordinates do not change anymore). In a similar manner, we can process all our trajectories and plot them all together: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = gpd.GeoDataFrame()\n",
    "\n",
    "i = 0\n",
    "for trajectory in collection.trajectories:\n",
    "    # Calculate speed\n",
    "    trajectory.add_speed(overwrite=True)\n",
    "    \n",
    "    # Determine direction of movement\n",
    "    trajectory.add_direction(overwrite=True)\n",
    "    \n",
    "    # Parse time component (as datetime)\n",
    "    trajectory.df[\"t\"] = pd.to_datetime(trajectory.df[\"Timestamp\"])\n",
    "    \n",
    "    # Add unique id for each trajectory\n",
    "    trajectory.df[\"tid\"] = i\n",
    "    \n",
    "    # Add to container\n",
    "    trajectories = trajectories.append(trajectory.df)\n",
    "    i+=1\n",
    "    \n",
    "# Reorder the data based on timestamp\n",
    "trajectories = trajectories.sort_values(by=\"t\").reset_index(drop=True)\n",
    "\n",
    "# Plot them all (use trajectory id to separate trajectories)\n",
    "fig = px.line_3d(trajectories, x=\"x\", y=\"y\", z=\"t\", color='MMSI')\n",
    "fig.update_traces(line=dict(width=5))\n",
    "\n",
    "# Want to get background map as well? It is possible:\n",
    "# https://chart-studio.plotly.com/~empet/14397/plotly-plot-of-a-map-from-data-available/#/\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3D visualization of multiple trajectories can look a bit messy (a bit like spaghetty), but we can already identify some patterns from the spate-time data. Looking at how the trajectories cluster in the STC, it is evident that there is a lot of activity throughout the day. There are two clear clusters in the data which basically represent activity related to two harbors in the area (Gothenburgs harbor and Saltholmens Brygga). From the data you can see how ships and boats are steadily approaching the harbors using more or less the same routes (at different times). Looking at the data, we can also see that one ship stayed the whole day in the harbor without moving anywhere (vertical line without movement). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating trajectories\n",
    "\n",
    "As we can saw from the previous examples, looking at the movement data in 3D using STC can provide interesting insights that can be tricky to understand otherwise. However, understanding and reading the information takes a bit of time and experience before you start to understand what is going on in the data. There are however more tricks that we can do, to abstract our data and make it easier to understand in 2D. Movingpandas provides a handy tool called ``TrajectoryCollectionAggregator`` which can be used to aggregate the trajectories by extracting clusters of significant trajectory points and computing flows between the clusters. These significant points of trajectories include e.g. their start and end points, the points of significant turns, and the points of significant stops, i.e. pauses in the movement (Andrienko & Andrienko, 2011). Once the points have been detected, then they are grouped based on their spatial proximity and flows are generated between them. We can aggregate the movement data following this approach easily with movingpandas, by specifying minimum and maximum threshold distances between significant points and minimum duration (in seconds) required to detect a stop from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate trajectories\n",
    "# Method description: https://movingpandas.readthedocs.io/en/latest/trajectoryaggregator.html\n",
    "agg = mpd.TrajectoryCollectionAggregator(collection, min_distance=500, max_distance=2000, min_stop_duration=timedelta(minutes=10))\n",
    "\n",
    "# Get flows and clusters\n",
    "flows = agg.get_flows_gdf()\n",
    "clusters = agg.get_clusters_gdf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, we get DataFrames having information about weight of the flows as well as the size of the cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this information, we can create an interactive map that provides more easily understandable view for our spatio-temporal movement data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot with Holoviews\n",
    "( flows.hvplot(title='Generalized aggregated trajectories', geo=True, hover_cols=['weight'], line_width='weight', alpha=0.5, color='#1f77b3', tiles='OSM', frame_height=400, frame_width=400) * \n",
    "  clusters.hvplot(geo=True, color='red', size='n') )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! As a result, we have a map which is quite easy to interpret with width of the line representing the volume of vessels moving between specific locations. We were able to get a sense of these patterns by looking at the movement data in 3D (i.e. where lot's of movement happens), but following this aggregation approach and visualizing the movement flows makes it much easier to get a grasp of the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Animating and exploring the trajectory characteristics in 3D \n",
    "\n",
    "The previous approaches have provided useful ways to extract information from movement data. Next, we will see how we can extract further characteristics based on the data using a WebGL based interactive visualization tool developed by Uber: [Kepler.gl](https://kepler.gl/).\n",
    "\n",
    "Let's first manipulate our movement data a bit so that we can visualize it easily in 3D using Kepler.gl. Basically, what we want to do is to generate line segments between all observations in our data and convert them into Polygons by making a small buffer around them. This trick is needed to be able to take advantage of the full 3D capabilities of Kepler.gl. Let's start by preparing a couple of helper functions that generates the segments and converts them into a Polygon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import LineString\n",
    "\n",
    "def to_linestring(row):\n",
    "    if row[\"end_geometry\"] is not None:\n",
    "        return LineString([row[\"geometry\"], row[\"end_geometry\"]])\n",
    "\n",
    "def prepare_segments(trajectory):\n",
    "    # Calculate segments for a single trajectory\n",
    "    df = trajectory.df.join((trajectory.df[\"geometry\"].shift(-1).to_frame().rename(columns={'geometry': 'end_geometry'})))\n",
    "\n",
    "    # Create linestring\n",
    "    df[\"segment\"] = df[[\"geometry\", \"end_geometry\"]].apply(to_linestring, axis=1)\n",
    "\n",
    "    # Update geometry column with segments\n",
    "    df[\"geometry\"] = df[\"segment\"]\n",
    "\n",
    "    # Drop empty geoms (there is one after converting from points to lines)\n",
    "    df = df.dropna(subset=[\"geometry\"])\n",
    "\n",
    "    # Drop unnecessary columns\n",
    "    df = df.drop([\"segment\", \"end_geometry\"], axis=1)\n",
    "\n",
    "    # Convert lines to polygons, so that volume/height can be adjusted\n",
    "    df[\"geometry\"] = df.buffer(0.0002)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movements = gpd.GeoDataFrame()\n",
    "\n",
    "for trajectory in collection.trajectories:\n",
    "    \n",
    "    # Parse direction of movement\n",
    "    trajectory.add_direction(overwrite=True)\n",
    "\n",
    "    # Parse speed\n",
    "    trajectory.add_speed(overwrite=True)\n",
    "\n",
    "    # Create segments and calculate some useful statistics\n",
    "    segments = prepare_segments(trajectory)\n",
    "    movements = movements.append(segments)\n",
    "    \n",
    "    # Increase index\n",
    "    i+=1\n",
    "    \n",
    "# Reset index\n",
    "movements = movements.reset_index(drop=True)\n",
    "\n",
    "# Drop \"time\" column which is in datetime format (Kepler.gl don't like it when saving the output)\n",
    "movements = movements.drop([\"time\"], axis=1)\n",
    "\n",
    "# What did we get?\n",
    "movements.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now we have prepared our data and we can visualize it with Kepler.gl. What we will do next is to:\n",
    "\n",
    "1. Determine the attribute which is used for coloring the trajectories (name)\n",
    "2. Determine that the height of data is based on the speed so that we can easily see areas and segments where the ships/boats have been moving fast\n",
    "3. Add a filter based on timestamp\n",
    "4. Add another filter based on ship type\n",
    "5. Animate the movements with a selected time window\n",
    "\n",
    "Notice, that these will be done using the graphical interface of Kepler.gl, hence, you need to check the video to understand how to repeat the steps. Initializing the Kepler.gl and adding our movement data to it is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a basemap \n",
    "m = KeplerGl(height=800, width=800)\n",
    "\n",
    "# Add the movement data\n",
    "m.add_data(movements, \"trajectories\")\n",
    "\n",
    "# Render the map / interface\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once, we have prepared our visualization in a way how we want it, we can easily save our map into a dedicated html website with the current state of the page by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save_to_html(file_name='Trajectories_3D.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
